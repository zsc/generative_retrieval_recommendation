# 第5章：生成式检索的训练策略

生成式检索将文档检索问题转化为序列生成任务，这带来了独特的训练挑战。与传统的判别式检索模型不同，生成式模型需要直接"记住"整个文档集合，并学会根据查询精确生成文档标识符。本章深入探讨如何有效训练这类模型，包括预训练策略、文档记忆化技术、数据增强方法，以及提升模型鲁棒性的高级技术。我们将重点关注如何在有限的模型容量下编码海量文档信息，以及如何设计训练目标使模型既能准确记忆又能灵活泛化。

## 5.1 预训练与微调流程

生成式检索的训练流程与传统检索系统有本质区别。传统系统通常独立训练查询编码器和文档编码器，然后通过相似度计算进行匹配。而生成式检索将整个过程统一到一个序列生成框架中，这带来了独特的训练挑战：模型不仅要理解查询语义，还要能够精确记忆并生成文档标识符。这种端到端的训练方式要求我们重新思考预训练和微调的策略。

### 5.1.1 预训练目标设计

生成式检索模型的预训练是一个多目标优化问题。与纯语言模型不同，我们需要在预训练阶段就开始建立查询-文档的关联，同时保持模型的语言理解能力。这种双重需求导致了独特的预训练目标设计。

**1. 文档标识符预测（Document ID Prediction）**

文档标识符预测是生成式检索的基础任务。给定文档内容 $d$，模型需要生成对应的标识符序列 $id = (t_1, t_2, ..., t_n)$。这个过程可以看作是一种"压缩编码"，将长文档压缩成短标识符：

$$\mathcal{L}_{doc2id} = -\sum_{i=1}^{n} \log p(t_i | t_{<i}, d; \theta)$$

这个目标的关键在于如何设计标识符。随机标识符虽然简单，但模型难以学习其模式；语义标识符（如层次化类别路径）则提供了额外的结构信息，有助于模型泛化。实践中，我们常常采用混合策略：高层使用语义信息（如类别），底层使用学习得到的编码。

训练时需要注意的是，文档到ID的映射应该是单射的（一对一），但在实际场景中可能存在重复文档。处理重复的策略包括：保留第一个出现的文档、合并重复文档的查询集合、或者为重复文档分配相同的标识符前缀但不同的后缀。

**2. 查询-文档对齐（Query-Document Alignment）**

查询-文档对齐是检索的核心任务。不同于传统的双塔模型分别编码查询和文档，生成式方法直接建模条件概率 $p(id_d | q)$：

$$\mathcal{L}_{q2id} = -\sum_{(q,d) \in \mathcal{D}_{train}} \log p(id_d | q; \theta)$$

这个目标的优势在于可以利用查询和文档之间的交互注意力（cross-attention），捕获更细粒度的语义匹配信号。但挑战在于训练数据的稀疏性：大多数查询只与少数文档相关，这导致正样本稀缺。

为了缓解数据稀疏问题，我们可以采用多种策略：
- **查询扩展**：为每个文档生成多个可能的查询变体
- **相关性传播**：利用文档之间的相似性，将查询的相关性传播到相似文档
- **弱监督学习**：利用点击日志等隐式反馈作为弱标签

**3. 双向建模（Bidirectional Modeling）**

双向建模同时训练查询到文档（Q2D）和文档到查询（D2Q）两个方向的生成：

$$\mathcal{L}_{bi} = \alpha \mathcal{L}_{q2id} + (1-\alpha) \mathcal{L}_{id2q}$$

其中 $\alpha$ 是平衡系数，通常设为0.5。$\mathcal{L}_{id2q}$ 是从文档标识符生成查询的损失：

$$\mathcal{L}_{id2q} = -\sum_{(q,d) \in \mathcal{D}_{train}} \log p(q | id_d; \theta)$$

双向建模的好处是多方面的：
- **数据效率**：同一批数据可以用于两个方向的训练，提高数据利用率
- **正则化效果**：D2Q任务可以看作是Q2D任务的正则化，防止模型过拟合
- **查询生成**：训练好的D2Q模型可以用于生成伪查询，进一步扩充训练数据

但双向建模也有潜在问题。两个任务可能存在冲突，特别是当使用共享参数时。一种解决方案是使用任务特定的前缀或适配器，让模型根据任务类型调整其行为。

### 5.1.2 多阶段训练策略

生成式检索的训练不是一蹴而就的，而是需要精心设计的多阶段流程。每个阶段都有特定的目标和挑战，前一阶段为后一阶段奠定基础。这种渐进式的训练策略源于一个关键观察：直接让随机初始化的模型同时学习语言理解、文档记忆和检索对齐几乎是不可能的。

```
阶段1：通用语言模型预训练
   ↓ (迁移语言理解能力)
阶段2：文档记忆化训练
   ↓ (建立文档-ID映射)
阶段3：查询-文档对齐微调
   ↓ (优化检索性能)
阶段4：任务特定优化
```

**阶段1：通用预训练**

第一阶段利用大规模无标注文本进行语言模型预训练。这个阶段的目标是让模型获得基础的语言理解能力，包括词汇语义、句法结构和常识知识。常用的预训练目标包括：

- **掩码语言建模（MLM）**：随机掩盖输入中的部分词汇，要求模型预测被掩盖的内容
- **因果语言建模（CLM）**：给定前文预测下一个词，适用于生成式模型架构
- **去噪自编码（DAE）**：对输入添加噪声（如删除、替换、打乱），要求模型恢复原始输入

实践中，我们通常直接使用现有的预训练模型（如T5、BART、GPT），这样可以节省大量的计算资源。选择预训练模型时需要考虑：
- 模型架构是否适合生成任务（编码器-解码器 vs 纯解码器）
- 模型规模与文档集合大小的匹配（更大的文档集需要更大的模型容量）
- 预训练数据与目标领域的相关性（领域特定模型可能效果更好）

**阶段2：文档记忆化**

文档记忆化是生成式检索独有的关键阶段。在这个阶段，模型需要将文档集合"烙印"到参数中。这不是简单的过拟合，而是一种结构化的记忆过程。

记忆化训练的核心策略：
- **全文档覆盖**：确保每个文档都被模型"看到"足够多次（通常需要几十到几百个epoch）
- **均衡采样**：避免高频文档主导训练，使用重要性采样或者固定每个文档的曝光次数
- **渐进难度**：先记忆短文档和简单ID，再处理长文档和复杂ID
- **记忆验证**：定期测试模型能否从文档内容准确生成ID，记忆准确率应达到90%以上

训练技巧：
```python
# 记忆化训练的学习率调度
lr_schedule = {
    'warmup': 1e-4,    # 预热阶段，快速适应
    'main': 5e-5,      # 主训练阶段，稳定记忆
    'refinement': 1e-5 # 精修阶段，巩固记忆
}
```

监控指标：
- **精确匹配率**：完整正确生成ID的比例
- **前缀匹配率**：正确生成ID前缀的比例（用于层次化ID）
- **记忆容量利用率**：模型参数的信息熵，反映记忆效率

**阶段3：检索微调**

有了文档记忆基础后，第三阶段专注于学习查询-文档的语义对齐。这个阶段引入真实的检索任务，让模型学会根据查询的语义选择正确的文档。

微调策略的关键点：
- **保护记忆**：使用较低的学习率，避免破坏已建立的文档记忆
- **对比学习**：引入负样本，让模型学会区分相关和不相关文档
- **多任务平衡**：同时优化多个检索指标（如精确率、召回率、排序质量）

数据组织：
```python
# 每个批次的数据组成
batch = {
    'positive_pairs': [(q1, d1), (q2, d2), ...],  # 正样本对
    'hard_negatives': [(q1, d1'), (q2, d2'), ...], # 困难负样本
    'random_negatives': [(q1, d1''), ...],         # 随机负样本
    'weights': [w1, w2, ...]                       # 样本权重
}
```

损失函数设计：
$$\mathcal{L}_{retrieval} = \mathcal{L}_{positive} + \lambda_1 \mathcal{L}_{hard\_neg} + \lambda_2 \mathcal{L}_{random\_neg}$$

其中不同类型的负样本有不同的权重，困难负样本通常权重更高。

### 5.1.3 参数高效微调

随着预训练模型规模的不断增长（从BERT的3亿参数到GPT-3的1750亿参数），全参数微调变得越来越不现实。对于生成式检索，这个问题尤为突出：我们需要为不同的文档集合维护不同的模型，全参数微调意味着巨大的存储和计算开销。参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）技术应运而生，它们只更新模型的一小部分参数，就能达到接近全参数微调的效果。

**1. Adapter 层插入**

Adapter是最早被广泛采用的参数高效方法之一。核心思想是在预训练模型的每个Transformer层中插入小型的适配器模块，冻结原始参数，只训练这些适配器：

$$h' = h + f_{adapter}(h)$$

其中 $f_{adapter}$ 通常是一个瓶颈结构的前馈网络：

$$f_{adapter}(h) = W_{up} \cdot \text{ReLU}(W_{down} \cdot h)$$

这里 $W_{down} \in \mathbb{R}^{r \times d}$ 将输入降维到低维空间，$W_{up} \in \mathbb{R}^{d \times r}$ 再映射回原始维度。瓶颈维度 $r$ 通常远小于隐藏维度 $d$（如 $r = 64$，$d = 768$）。

Adapter在生成式检索中的优势：
- **模块化设计**：可以为不同文档集训练不同的adapter，共享基础模型
- **快速切换**：通过更换adapter实现快速的领域适应
- **增量学习**：新文档可以通过训练新的adapter层来记忆，不影响已有知识

实践考虑：
- Adapter的插入位置很重要，通常在自注意力层和前馈层之后各插入一个
- 瓶颈维度的选择需要权衡：太小影响表达能力，太大失去参数效率优势
- 可以使用不同大小的adapter处理不同复杂度的任务

**2. Prefix Tuning**

Prefix Tuning的思想是在输入序列前添加一组可学习的"软提示"（soft prompts），这些连续向量可以引导模型的生成行为：

$$p(y|x) = p(y | [P_\theta; x])$$

其中 $P_\theta \in \mathbb{R}^{l \times d}$ 是长度为 $l$ 的前缀向量序列。与离散的提示词不同，这些向量是连续的、可通过梯度下降优化的。

在生成式检索中，前缀可以编码任务特定信息：
- **文档集特征**：不同领域的文档集使用不同的前缀
- **查询类型**：导航型查询、信息型查询使用不同前缀
- **用户偏好**：个性化检索可以为每个用户学习特定前缀

前缀的设计策略：
```python
# 层次化前缀设计
prefix = {
    'global': learned_vectors_global,      # 全局任务前缀
    'domain': learned_vectors_domain,      # 领域特定前缀
    'task': learned_vectors_task,         # 具体任务前缀
}
# 拼接使用
full_prefix = concat([prefix['global'], prefix['domain'], prefix['task']])
```

优化技巧：
- **重参数化**：通过MLP重参数化前缀，增加表达能力
- **层特定前缀**：不同Transformer层使用不同的前缀向量
- **前缀初始化**：使用任务相关的离散提示初始化，加速收敛

**3. LoRA（Low-Rank Adaptation）**

LoRA是目前最流行的参数高效方法之一。其核心思想是将权重更新分解为两个低秩矩阵的乘积：

$$W' = W + \Delta W = W + BA$$

其中 $B \in \mathbb{R}^{d \times r}$，$A \in \mathbb{R}^{r \times k}$，秩 $r \ll \min(d, k)$。

这种分解大幅减少了可训练参数：
- 原始参数量：$d \times k$
- LoRA参数量：$r \times (d + k)$
- 压缩比：当 $r = 8$，$d = k = 768$ 时，压缩比约为 96:1

LoRA在生成式检索中的应用：
- **选择性应用**：通常只在注意力层的 $W_q$ 和 $W_v$ 矩阵上应用
- **多任务学习**：不同任务使用不同的LoRA权重，基础模型共享
- **动态秩调整**：根据任务复杂度调整秩 $r$

实现细节：
```python
class LoRALayer:
    def __init__(self, d, k, r=8, alpha=16):
        self.A = init_normal(r, k, std=1/sqrt(r))
        self.B = init_zeros(d, r)  # B初始化为0
        self.scaling = alpha / r    # 缩放因子
    
    def forward(self, x, W):
        # 原始计算 + LoRA增量
        return W @ x + self.scaling * (self.B @ (self.A @ x))
```

**4. 混合方法与选择策略**

不同的参数高效方法各有优劣，实践中常常结合使用：

| 方法 | 参数效率 | 性能 | 训练速度 | 推理开销 |
|------|---------|------|----------|----------|
| Adapter | 中 | 良好 | 快 | 有额外计算 |
| Prefix | 高 | 良好 | 快 | 增加序列长度 |
| LoRA | 高 | 优秀 | 快 | 可合并无开销 |

选择建议：
- **大规模部署**：LoRA（推理时可合并到原权重，无额外开销）
- **多任务场景**：Adapter（模块化设计，易于管理）
- **小数据场景**：Prefix Tuning（参数最少，不易过拟合）
- **混合使用**：LoRA + Prefix，结合两者优势

## 5.2 文档记忆化技术

### 5.2.1 记忆化的本质

文档记忆化是生成式检索的核心挑战。模型需要将文档集合 $\mathcal{D}$ 编码到参数 $\theta$ 中：

$$\theta^* = \arg\min_\theta \sum_{d \in \mathcal{D}} \mathcal{L}_{mem}(d, \theta)$$

关键问题是如何在有限的参数空间中高效存储文档信息。

### 5.2.2 分层记忆策略

为了提高记忆效率，可以采用分层编码：

**1. 文档聚类与层次化标识符**

```
Level 1: 主题类别 (如 "体育")
    ↓
Level 2: 子类别 (如 "篮球")
    ↓
Level 3: 具体文档 ID
```

这种层次结构允许模型共享高层语义信息，减少记忆负担。

**2. 渐进式记忆**

按重要性逐步记忆文档：

```python
# 伪代码
for epoch in range(num_epochs):
    if epoch < warmup_epochs:
        # 先记忆高频/重要文档
        train_on_top_k_docs(k=1000)
    else:
        # 逐步扩展到全部文档
        train_on_all_docs()
```

### 5.2.3 记忆增强技术

**1. 外部记忆模块**

引入可微分的外部记忆：

$$M \in \mathbb{R}^{N \times d}$$

其中 $N$ 是记忆槽位数，$d$ 是向量维度。

读取操作：
$$r = \sum_{i=1}^{N} \alpha_i M_i$$

其中 $\alpha_i$ 是注意力权重。

**2. 稀疏激活**

使用稀疏激活减少干扰：

$$h = \text{TopK}(\text{ReLU}(Wx + b))$$

只激活最相关的神经元，避免记忆冲突。

### 5.2.4 防止灾难性遗忘

当新文档加入时，需要防止遗忘已学习的文档：

**1. 弹性权重巩固（EWC）**

$$\mathcal{L}_{EWC} = \mathcal{L}_{new} + \lambda \sum_i F_i (\theta_i - \theta_i^*)^2$$

其中 $F_i$ 是 Fisher 信息矩阵的对角元素。

**2. 记忆回放**

定期回放旧文档样本：

$$\mathcal{L}_{total} = \mathcal{L}_{current} + \beta \mathcal{L}_{replay}$$

## 5.3 查询生成与数据增强

### 5.3.1 伪查询生成

生成式检索的训练需要大量的查询-文档对。当真实查询稀缺时，可以自动生成伪查询：

**1. 基于文档的查询生成**

使用序列到序列模型从文档生成可能的查询：

$$q_{pseudo} = \arg\max_q p(q | d; \phi)$$

其中 $\phi$ 是查询生成模型的参数。

**2. 模板基查询扩展**

使用预定义模板生成查询变体：

```
原始查询: "深度学习教程"
变体1: "如何学习深度学习"
变体2: "深度学习入门指南"
变体3: "深度学习基础知识"
```

**3. 回译增强（Back-translation）**

通过翻译往返生成查询变体：

```
中文 → 英文 → 中文
"机器学习算法" → "machine learning algorithms" → "机器学习算法/ML算法"
```

### 5.3.2 负样本构造策略

有效的负样本对于训练判别能力至关重要：

**1. 随机负采样**

从文档集合中随机采样负样本：

$$\mathcal{D}_{neg}^{random} = \text{RandomSample}(\mathcal{D} \setminus \{d^+\}, k)$$

**2. 困难负样本挖掘**

选择与查询相似但不相关的文档：

$$d_{hard}^- = \arg\max_{d \in \mathcal{D}^-} \text{sim}(q, d)$$

其中 $\text{sim}$ 是相似度函数（如余弦相似度）。

**3. 批内负样本（In-batch Negatives）**

利用批次内其他样本的文档作为负样本：

```python
# 批次大小为 B
for i in range(B):
    positive = docs[i]  # 正样本
    negatives = docs[:i] + docs[i+1:]  # 其他 B-1 个作为负样本
```

### 5.3.3 数据增强技术

**1. 文档扰动**

对文档内容进行轻微修改：

- **词汇替换**：用同义词替换部分词汇
- **句子重排**：改变句子顺序但保持语义
- **摘要生成**：使用文档摘要作为额外训练样本

**2. 查询改写**

生成语义相同但表达不同的查询：

```
原始: "Python编程入门"
改写1: "如何开始学习Python"
改写2: "Python初学者教程"
改写3: "零基础学Python"
```

**3. 跨语言增强**

利用多语言数据：

$$\mathcal{L}_{cross} = \mathcal{L}(q_{en}, d_{zh}) + \mathcal{L}(q_{zh}, d_{en})$$

### 5.3.4 课程学习策略

按难度递增的顺序组织训练数据：

**1. 简单到复杂**

```
阶段1: 精确匹配查询 (exact match)
阶段2: 同义词查询 (synonym queries)  
阶段3: 语义相关查询 (semantic queries)
阶段4: 复杂推理查询 (reasoning queries)
```

**2. 动态难度调整**

根据模型性能自适应调整样本难度：

$$p(sample_i) \propto \exp(-\alpha \cdot \text{accuracy}_i)$$

准确率高的样本降低采样概率，让模型专注于困难样本。

## 5.4 高级话题：对抗训练与鲁棒性提升

### 5.4.1 对抗样本生成

生成式检索模型容易受到对抗攻击。通过对抗训练可以提升鲁棒性：

**1. 查询扰动攻击**

在查询嵌入空间添加对抗扰动：

$$q_{adv} = q + \epsilon \cdot \text{sign}(\nabla_q \mathcal{L})$$

其中 $\epsilon$ 控制扰动强度。

**2. 文档污染攻击**

恶意修改文档内容以操纵检索结果：

```
原始文档: "深度学习是机器学习的分支..."
污染文档: "深度学习是机器学习的分支... [隐藏关键词: 赌博、贷款]"
```

### 5.4.2 防御机制

**1. 对抗训练目标**

$$\mathcal{L}_{robust} = \mathcal{L}_{clean} + \lambda \max_{\|\delta\| \leq \epsilon} \mathcal{L}(x + \delta, y)$$

同时优化干净样本和对抗样本的性能。

**2. 梯度正则化**

限制模型对输入扰动的敏感度：

$$\mathcal{L}_{grad} = \|\nabla_x \mathcal{L}\|_2^2$$

**3. 集成防御**

训练多个模型并集成预测：

$$p_{ensemble}(d|q) = \frac{1}{M} \sum_{i=1}^{M} p_i(d|q)$$

### 5.4.3 鲁棒性评估

**1. 扰动鲁棒性测试**

评估模型对不同类型扰动的抵抗力：

- 字符级扰动（拼写错误）
- 词级扰动（同义词替换）
- 句子级扰动（改写）

**2. 分布偏移适应**

测试模型对数据分布变化的适应能力：

$$\text{RobustScore} = \frac{\text{Performance}_{ood}}{\text{Performance}_{id}}$$

其中 OOD 是分布外数据，ID 是分布内数据。

## 5.5 工业案例：阿里巴巴电商搜索的生成式改造

### 背景与挑战

阿里巴巴的电商搜索系统每天处理数十亿次查询，覆盖数亿商品。传统的倒排索引+排序的两阶段架构面临以下挑战：

1. **语义鸿沟**：用户查询与商品标题存在表达差异
2. **长尾查询**：大量低频查询缺乏训练数据  
3. **实时性要求**：新商品需要快速被检索到
4. **多模态需求**：用户期望图片搜索、语音搜索

### 生成式检索架构

阿里巴巴在2022-2023年逐步引入生成式检索，采用混合架构：

```
用户查询
    ↓
[查询理解层]
    ↓
并行检索 ┌─────────────┬──────────────┐
        │传统倒排索引│ 生成式检索器 │
        └─────────────┴──────────────┘
                ↓
            [融合排序]
                ↓
            搜索结果
```

### 关键技术创新

**1. 商品ID体系重构**

从随机ID改为语义化层次ID：

```
原始ID: SKU_20394857
新ID: 电子/手机/苹果/iPhone15Pro
```

这种设计使得模型可以通过前缀共享学习类目知识。

**2. 亿级商品的增量学习**

采用"基座模型+增量适配器"架构：

- 基座模型：覆盖核心80%商品（更新周期：月）
- 增量适配器：处理新商品和季节性商品（更新周期：小时）

**3. 查询意图解耦**

将复杂查询分解为多个子意图：

```
原始查询: "适合送给妈妈的生日礼物不要太贵"
分解:
- 商品属性: 礼物
- 使用场景: 生日
- 目标用户: 中年女性
- 价格约束: 中低价位
```

每个子意图独立生成候选，最后融合。

### 训练优化策略

**1. 多任务学习框架**

$$\mathcal{L}_{total} = \lambda_1 \mathcal{L}_{retrieval} + \lambda_2 \mathcal{L}_{click} + \lambda_3 \mathcal{L}_{purchase}$$

同时优化检索相关性、点击率和购买转化。

**2. 用户行为序列建模**

利用用户历史行为增强查询理解：

```python
user_embedding = encode_behavior_sequence(clicks, purchases)
query_enhanced = concat([query, user_embedding])
```

**3. 负反馈学习**

从"零结果"查询中学习：

- 收集导致无结果的查询
- 分析失败原因（拼写错误、新概念、表达差异）
- 生成纠正样本进行训练

### 实施效果

经过一年的迭代优化，生成式检索在阿里巴巴电商搜索中取得显著成果：

- **覆盖率提升**：长尾查询覆盖率提升35%
- **相关性改善**：用户满意度提升8.2%
- **新品曝光**：新商品在上架24小时内的曝光量提升60%
- **计算成本**：相比纯深度模型排序降低40%

### 经验教训

1. **渐进式迁移**：不要试图一次性替换整个系统，而是逐步引入生成式组件
2. **混合架构优势**：传统方法在精确匹配上仍有优势，混合架构能结合两者优点
3. **数据质量关键**：用户行为数据的清洗和标注质量直接影响模型效果
4. **在线学习必要**：电商场景变化快，需要持续的在线学习能力

## 本章小结

本章深入探讨了生成式检索的训练策略，涵盖了从预训练到部署的完整流程。关键要点包括：

**核心概念**：
- 生成式检索将检索问题转化为序列生成任务，需要专门的训练策略
- 多阶段训练（预训练→记忆化→微调）是提升性能的关键
- 文档记忆化是生成式检索的核心挑战，需要在有限参数空间编码海量信息

**关键技术**：
- **预训练策略**：结合语言建模和文档ID预测的多任务学习
- **记忆化技术**：分层编码、外部记忆、防止灾难性遗忘
- **数据增强**：伪查询生成、负样本构造、课程学习
- **鲁棒性提升**：对抗训练、梯度正则化、集成防御

**实践启示**：
- 参数高效微调（LoRA、Adapter）对大模型至关重要
- 混合架构结合传统检索和生成式方法效果最佳
- 持续学习和增量更新是工业部署的必要条件

## 练习题

### 基础题

**练习5.1**：解释为什么生成式检索需要文档记忆化阶段？如果直接从预训练模型开始查询-文档对齐训练会有什么问题？

<details>
<summary>提示（点击展开）</summary>
思考模型参数容量与文档集合规模的关系，以及冷启动问题。
</details>

<details>
<summary>参考答案（点击展开）</summary>
文档记忆化阶段必要的原因：
1. 参数容量限制：模型需要在有限参数中编码整个文档集合的信息
2. 冷启动问题：没有记忆化，模型无法生成有效的文档ID
3. 训练效率：直接对齐训练收敛极慢，因为模型需要同时学习记忆和对齐
4. 泛化能力：先记忆后对齐有助于模型建立文档空间的结构化理解
</details>

**练习5.2**：设计一个负样本构造策略，使得模型能够区分语义相似但实际不相关的文档。

<details>
<summary>提示（点击展开）</summary>
考虑同一类别下的不同实体，或者表面相似但语义不同的文档。
</details>

<details>
<summary>参考答案（点击展开）</summary>
策略设计：
1. 类内负采样：从相同类别选择不同实体（如"iPhone 14"vs"iPhone 15"）
2. 关键词重叠负样本：选择关键词重叠但主题不同的文档
3. 语义相似负样本：使用预训练编码器找到余弦相似度0.7-0.9之间的文档
4. 时间敏感负样本：对时效性查询，选择过期的相关文档作为负样本
</details>

**练习5.3**：计算题：假设模型有10B参数，每个参数32位，需要记忆1000万个文档，每个文档平均需要多少bit的参数容量？

<details>
<summary>提示（点击展开）</summary>
计算总参数容量，然后除以文档数量。
</details>

<details>
<summary>参考答案（点击展开）</summary>
计算过程：
- 总参数容量 = 10B × 32 bits = 320B bits
- 文档数 = 10M = 10^7
- 每个文档容量 = 320B / 10M = 32,000 bits = 4KB
这说明即使是大模型，每个文档的平均容量也很有限，需要高效编码。
</details>

### 挑战题

**练习5.4**：设计一个增量学习方案，使得生成式检索模型能够每天接收新文档而不需要完全重训练。

<details>
<summary>提示（点击展开）</summary>
考虑参数隔离、知识蒸馏、记忆回放等技术的组合。
</details>

<details>
<summary>参考答案（点击展开）</summary>
增量学习方案设计：
1. 双模型架构：维护基础模型（月更新）+ 增量模型（日更新）
2. 参数隔离：为新文档分配专用的adapter参数
3. 知识蒸馏：从旧模型蒸馏知识防止遗忘
4. 采样策略：80%新文档 + 20%旧文档回放
5. ID预留：预留ID空间给新文档，避免ID冲突
6. 定期合并：每月将增量知识合并到基础模型
</details>

**练习5.5**：分析对抗训练在生成式检索中的计算开销，并提出一个高效的对抗训练方案。

<details>
<summary>提示（点击展开）</summary>
考虑对抗样本生成的成本和训练时间的权衡。
</details>

<details>
<summary>参考答案（点击展开）</summary>
计算开销分析：
- 标准训练：1次前向 + 1次反向
- 对抗训练：2次前向（干净+对抗）+ 2次反向 + 对抗样本生成
- 开销增加：约2.5-3倍

高效方案：
1. 异步对抗样本生成：使用独立进程预生成对抗样本
2. 对抗样本缓存：重用历史对抗样本
3. 选择性对抗：只对高价值查询进行对抗训练
4. Fast Gradient Method：使用单步攻击而非迭代攻击
5. 周期性对抗：每N个batch才进行一次对抗训练
</details>

**练习5.6**：开放思考题：如何设计一个自适应的训练策略，根据模型在不同类型查询上的表现动态调整训练重点？

<details>
<summary>提示（点击展开）</summary>
考虑在线评估、多臂老虎机、元学习等方法。
</details>

<details>
<summary>参考答案（点击展开）</summary>
自适应训练策略设计：
1. 性能监控：实时跟踪不同查询类型的准确率
2. 动态采样：根据性能反比例调整各类查询的采样权重
3. 难度感知：识别困难样本，增加其训练频率
4. 多臂老虎机：将不同训练策略视为臂，动态选择
5. 元学习器：训练一个元模型预测最优训练策略
6. 在线A/B测试：并行训练多个变体，选择最优
7. 反馈循环：收集用户反馈，识别失败模式并针对性改进
</details>

## 常见陷阱与错误

### 1. 记忆化不充分
**问题**：模型在训练时表现良好，但推理时无法生成有效的文档ID
**原因**：记忆化阶段训练不足，模型没有真正"记住"文档
**解决**：增加记忆化轮数，使用更低的学习率，验证模型能否从内容重建ID

### 2. 负样本过于简单
**问题**：模型在测试集上表现差，容易返回语义无关但表面相似的文档
**原因**：训练时的负样本过于简单（如随机采样），模型没有学会细粒度区分
**解决**：使用困难负样本挖掘，增加语义相似但不相关的负样本

### 3. 过拟合查询分布
**问题**：模型对训练集中的高频查询表现很好，但泛化能力差
**原因**：训练数据分布不均，模型过度拟合高频模式
**解决**：使用查询生成和数据增强，平衡训练数据分布

### 4. 灾难性遗忘
**问题**：增量学习新文档后，模型忘记了旧文档
**原因**：没有适当的记忆保护机制
**解决**：使用EWC、记忆回放或参数隔离技术

### 5. 解码效率低下
**问题**：生成式检索推理速度慢，无法满足在线服务要求
**原因**：自回归解码本质上是串行的，beam search进一步增加计算量
**解决**：使用前缀树约束、非自回归解码或缓存机制

## 最佳实践检查清单

### 训练前准备
- [ ] 文档ID设计是否考虑了语义信息和层次结构？
- [ ] 是否准备了充足的查询-文档对训练数据？
- [ ] 是否设计了合理的评估指标和测试集？
- [ ] 是否确定了模型规模与文档集合的匹配关系？

### 训练策略
- [ ] 是否采用了多阶段训练（预训练→记忆化→微调）？
- [ ] 是否使用了参数高效的微调方法（LoRA/Adapter）？
- [ ] 是否设计了有效的负样本构造策略？
- [ ] 是否应用了数据增强技术？
- [ ] 是否考虑了防止灾难性遗忘的机制？

### 优化技巧
- [ ] 是否使用了课程学习逐步增加训练难度？
- [ ] 是否监控了训练过程中的记忆化程度？
- [ ] 是否平衡了不同类型查询的训练比例？
- [ ] 是否定期评估模型的鲁棒性？

### 工程实践
- [ ] 是否设计了增量更新机制？
- [ ] 是否优化了推理效率（前缀树、缓存）？
- [ ] 是否准备了回退机制（混合检索）？
- [ ] 是否建立了监控和告警系统？
- [ ] 是否考虑了A/B测试方案？

### 部署验证
- [ ] 是否在真实数据上验证了模型效果？
- [ ] 是否测试了模型的延迟和吞吐量？
- [ ] 是否评估了模型的资源消耗？
- [ ] 是否准备了模型降级方案？
- [ ] 是否制定了持续优化计划？